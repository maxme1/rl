import gym
import torch

from rl_utils.dqn import DQN, epsilon_greedy_action, prepare_train_batch
import rl_utils.dqn as dqn
from rl_utils.interfaces.counter import Counter, periodic_decay
from rl_utils.interfaces.memory import FrameLimitMemory
from rl_utils.dqn import wrap_breakout

env_name = 'BreakoutNoFrameskip-v4'
env = wrap_breakout(gym.make(env_name))

eps_steps = 1e5
eps = Counter(periodic_decay(
    # lazy
    start_value=1, end_value=.001, steps=eps_steps, multiplier=.95
))

memory = FrameLimitMemory(1e5)

gamma = .99
stack_size = 4
train_batch = prepare_train_batch(
    # lazy
    batch_size=50, stack_size=stack_size
)
calculate_loss = dqn.calculate_loss(
    # lazy
    gamma=gamma
)
get_action = epsilon_greedy_action(
    # lazy
    get_eps=eps, sampler=env.action_space.sample, get_action=dqn.get_action
)
prepare_batch = dqn.prepare_batch(
    # lazy
    size=stack_size
)

agent = DQN(stack_size, env.action_space.n).cuda()
optimizer = torch.optim.Adam(agent.parameters(), lr=1e-4)
# get_lr = dqn.exponential_lr(
#     # lazy
#     initial=1e-4, multiplier=.1, step_length=4000, floordiv=False
# )
get_lr = None
min_steps = 100
